{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Loss: 0.44809776544570923, Param: tensor([[0.1000, 0.9000, 3.1000, 1.9000]], requires_grad=True)\n",
      "Iteration 11, Loss: 0.0021769609302282333, Param: tensor([[0.8895, 0.1191, 3.6313, 1.1061]], requires_grad=True)\n",
      "Iteration 21, Loss: 0.0006753954803571105, Param: tensor([[ 1.2231, -0.2127,  4.0209,  0.8201]], requires_grad=True)\n",
      "Iteration 31, Loss: 0.000526962336152792, Param: tensor([[ 1.3525, -0.3427,  4.3478,  0.8060]], requires_grad=True)\n",
      "Iteration 41, Loss: 0.00044421988422982395, Param: tensor([[ 1.4037, -0.3952,  4.6283,  0.8839]], requires_grad=True)\n",
      "Iteration 51, Loss: 0.00039250595727935433, Param: tensor([[ 1.4240, -0.4169,  4.8757,  0.9824]], requires_grad=True)\n",
      "Iteration 61, Loss: 0.00035758185549639165, Param: tensor([[ 1.4321, -0.4263,  5.0996,  1.0785]], requires_grad=True)\n",
      "Iteration 71, Loss: 0.00033222156343981624, Param: tensor([[ 1.4355, -0.4309,  5.3062,  1.1663]], requires_grad=True)\n",
      "Iteration 81, Loss: 0.0003128025564365089, Param: tensor([[ 1.4371, -0.4336,  5.4994,  1.2458]], requires_grad=True)\n",
      "Iteration 91, Loss: 0.00029785779770463705, Param: tensor([[ 1.4381, -0.4356,  5.6815,  1.3166]], requires_grad=True)\n",
      "\n",
      "\n",
      "\n",
      "Final Predicted Vector:  tensor([[0.0229, 0.9813, 0.9862, 0.0096]], grad_fn=<UnsafeViewBackward0>)\n",
      "GT Vector:  tensor([0., 1., 1., 0.])\n",
      "Final Permutation Matrix:  tensor([[0.0153, 0.3450, 0.6366, 0.0031],\n",
      "        [0.9737, 0.0156, 0.0073, 0.0034],\n",
      "        [0.0034, 0.0031, 0.0065, 0.9870],\n",
      "        [0.0076, 0.6363, 0.3496, 0.0064]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffsort import DiffSortNet\n",
    "\n",
    "# Using PyTorch's built-in BCE loss\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "vector_length = 2**2\n",
    "gt_vec = torch.tensor([0.0, 1.0, 1.0, 0.0])\n",
    "shuffled_vec = torch.tensor([1.0, 0.0, 0.0, 1.0])\n",
    "idxs = torch.randperm(vector_length, dtype=torch.float32, device='cpu').view(1,-1)\n",
    "idxs.requires_grad_(True)\n",
    "\n",
    "# sort using a bitonic-sorting-network\n",
    "sorter = DiffSortNet('bitonic', vector_length, steepness=15)\n",
    "\n",
    "optimizer = torch.optim.Adam([idxs], lr=0.1)\n",
    "\n",
    "for i in range(100):  # Example loop\n",
    "    sorted_vectors, permutation_matrices = sorter(idxs)\n",
    "    pred_vec = shuffled_vec@permutation_matrices\n",
    "    \n",
    "    loss = criterion(gt_vec.view(1,-1), pred_vec)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step the optimizer (this updates the parameter)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Optionally print the parameter's progress\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration {i+1}, Loss: {loss.item()}, Param: {idxs}')\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "print(\"Final Predicted Vector: \",  pred_vec)\n",
    "print(\"GT Vector: \", gt_vec)\n",
    "print(\"Final Permutation Matrix: \", permutation_matrices[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dered",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
